{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Define Imports"
      ],
      "metadata": {
        "id": "Lkhjw3gymQeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Concatenate, Input, Dropout, Dense\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "lTKe-FCMmPTy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Constants"
      ],
      "metadata": {
        "id": "Wb8aMvvhmY54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SENT_LEN = 150\n",
        "MAX_VOCAB_SIZE = 30000\n",
        "BATCH_SIZE = 200\n",
        "HIDDEN_DIM = 100\n",
        "N_EPOCHS = 10\n",
        "TEST_SPLIT_SIZE = 0.2\n",
        "FEATURE_LIMIT = 5000\n",
        "\n",
        "stance_map = {'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}\n",
        "stance_map_inv = {0: 'agree', 1: 'disagree', 2: 'discuss', 3: 'unrelated'}"
      ],
      "metadata": {
        "id": "Py07dTNRmYZf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Methods to Extract Data"
      ],
      "metadata": {
        "id": "UHMSZhbis_AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reads _bodies.csv file and creates a dictionary from Body ID -> Body Text\n",
        "def get_body_dict(data_dir):\n",
        "    with open(data_dir, encoding='utf_8') as tb:\n",
        "        train_bodies = list(csv.reader(tb))\n",
        "        train_bodies_dict = {}\n",
        "        for i, line in enumerate(tqdm(train_bodies)):\n",
        "            if i > 0:\n",
        "                id = int(line[0])\n",
        "                train_bodies_dict[id] = line[1]\n",
        "\n",
        "    return train_bodies_dict\n",
        "\n",
        "# Reads _stances.csv file and returns headline, body, stance data\n",
        "def get_article_data(data_dir, train_bodies_dict):\n",
        "    with open(data_dir, encoding='utf_8') as ts:\n",
        "        train_stances = list(csv.reader(ts))\n",
        "\n",
        "        headlines, bodies, stances = [], [], []\n",
        "\n",
        "        for i, line in enumerate(tqdm(train_stances)):\n",
        "            if i > 0:\n",
        "                body_id = int(line[1].strip())\n",
        "\n",
        "                stances.append(line[2].strip())\n",
        "                headlines.append(line[0].strip())\n",
        "                bodies.append(train_bodies_dict[body_id])\n",
        "        return stances, headlines, bodies"
      ],
      "metadata": {
        "id": "keNDYCpotkIK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in CSV Data"
      ],
      "metadata": {
        "id": "lj78REkwtJ9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Reading in CSV data...')\n",
        "train_bodies_dict = get_body_dict(\"train_bodies.csv\")\n",
        "train_stances, train_headlines, train_bodies = get_article_data(\"train_stances.csv\", train_bodies_dict)\n",
        "\n",
        "competition_bodies_dict = get_body_dict(\"competition_test_bodies.csv\")\n",
        "test_stances, test_headlines, test_bodies = get_article_data(\"competition_test_stances.csv\", competition_bodies_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h59xFqV9tPdo",
        "outputId": "d12645fb-674b-49f3-a32c-f805099b6abd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading in CSV data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1684/1684 [00:00<00:00, 496325.48it/s]\n",
            "100%|██████████| 49973/49973 [00:00<00:00, 665523.46it/s]\n",
            "100%|██████████| 905/905 [00:00<00:00, 560189.66it/s]\n",
            "100%|██████████| 25414/25414 [00:00<00:00, 565521.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build TFIDF Vectorizer and Vectorize Documents"
      ],
      "metadata": {
        "id": "JLLeKKEhxgy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Initializing TFIDF Vectorizer...')\n",
        "# Converts collection of raw documents to a TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer(max_features=FEATURE_LIMIT)\n",
        "# Builds vocabulary from training set\n",
        "vectorizer.fit(train_headlines + train_bodies)\n",
        "\n",
        "print('Vectorizing Data...')\n",
        "# Transform documents to document-term matrix\n",
        "x_train_headlines = vectorizer.transform(train_headlines).toarray()\n",
        "x_train_bodies = vectorizer.transform(train_bodies).toarray()\n",
        "x_test_headlines = vectorizer.transform(test_headlines).toarray()\n",
        "x_test_bodies = vectorizer.transform(test_bodies).toarray()"
      ],
      "metadata": {
        "id": "PR9pFWq9ZDZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04b74de-d16c-4291-a6a5-19f6cdf67312"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing TFIDF Vectorizer...\n",
            "Vectorizing Data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Stances and Create Train/Test Split"
      ],
      "metadata": {
        "id": "u1BMlkE809Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Encoding Stances...')\n",
        "# Fit encoder and return encoded labels\n",
        "encoded_train_stances = LabelEncoder().fit_transform(train_stances)\n",
        "# Transform labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(encoded_train_stances, num_classes=4)\n",
        "encoded_test_stances = LabelEncoder().fit_transform(test_stances)\n",
        "y_test = np_utils.to_categorical(encoded_test_stances, num_classes=4)\n",
        "\n",
        "print('Creating train/test splits...')\n",
        "x_train_headlines, x_val_headlines, x_train_bodies, x_val_bodies, y_train, y_val = train_test_split(\n",
        "  x_train_headlines, x_train_bodies, y_train, test_size=TEST_SPLIT_SIZE)"
      ],
      "metadata": {
        "id": "fifZW4hPZM-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973cf9e9-8c8b-4f6a-a9c0-8159f324c536"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding Stances...\n",
            "Creating train/test splits...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Model I/O"
      ],
      "metadata": {
        "id": "2FOIYiuQ4eA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Building Model I/O...')\n",
        "# Define model input for headlines\n",
        "input_headlines = Input(shape=(FEATURE_LIMIT,), name='input_headlines')\n",
        "# Define model input for bodies\n",
        "input_bodies = Input(shape=(FEATURE_LIMIT,), name='input_bodies')\n",
        "# Concatenate list of inputs\n",
        "concatenated_input = Concatenate()([input_headlines, input_bodies])\n",
        "\n",
        "# Add hidden layer\n",
        "hidden = Dense(HIDDEN_DIM, activation='sigmoid', name='dense_layer')(concatenated_input)\n",
        "# Add dropout layer\n",
        "hidden = Dropout(rate=0.6, name='dropout_layer')(hidden)\n",
        "# Add output layer\n",
        "out = Dense(4, activation='softmax', name='output_layer')(hidden)\n",
        "\n",
        "model = Model(inputs=[input_headlines, input_bodies], outputs=out)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di7kNOsRZrMl",
        "outputId": "35d74263-db75-43b5-a2ab-c77dcf6468eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Model I/O...\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_headlines (InputLayer)   [(None, 5000)]       0           []                               \n",
            "                                                                                                  \n",
            " input_bodies (InputLayer)      [(None, 5000)]       0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 10000)        0           ['input_headlines[0][0]',        \n",
            "                                                                  'input_bodies[0][0]']           \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 100)          1000100     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_layer (Dropout)        (None, 100)          0           ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 4)            404         ['dropout_layer[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,000,504\n",
            "Trainable params: 1,000,504\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and Fit Model"
      ],
      "metadata": {
        "id": "lgGZByLe6Qi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Compiling Model...')\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print('Fitting Model...')\n",
        "model.fit([x_train_headlines, x_train_bodies], y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "          validation_data=([x_val_headlines, x_val_bodies], y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGEwQBcvZ__z",
        "outputId": "d860f0be-4127-44e8-f371-7f736df0c192"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling Model...\n",
            "Fitting Model...\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 10s 47ms/step - loss: 0.9472 - accuracy: 0.6641 - val_loss: 0.7397 - val_accuracy: 0.7282\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.7920 - accuracy: 0.7237 - val_loss: 0.7073 - val_accuracy: 0.7333\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 11s 57ms/step - loss: 0.7372 - accuracy: 0.7357 - val_loss: 0.6849 - val_accuracy: 0.7392\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 9s 43ms/step - loss: 0.7075 - accuracy: 0.7425 - val_loss: 0.6637 - val_accuracy: 0.7419\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 9s 45ms/step - loss: 0.6856 - accuracy: 0.7462 - val_loss: 0.6443 - val_accuracy: 0.7474\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.6599 - accuracy: 0.7497 - val_loss: 0.6268 - val_accuracy: 0.7479\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 10s 49ms/step - loss: 0.6423 - accuracy: 0.7552 - val_loss: 0.6075 - val_accuracy: 0.7578\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.6236 - accuracy: 0.7590 - val_loss: 0.5952 - val_accuracy: 0.7568\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 10s 48ms/step - loss: 0.6077 - accuracy: 0.7651 - val_loss: 0.5767 - val_accuracy: 0.7676\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 9s 47ms/step - loss: 0.5923 - accuracy: 0.7672 - val_loss: 0.5650 - val_accuracy: 0.7713\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fada8acd810>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "laW5zm1m6UcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Model...')\n",
        "model.evaluate([x_test_headlines, x_test_bodies], y_test, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrt5dm3-aPPM",
        "outputId": "4d7cdd54-0b15-4417-8ec0-b96f259a41a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model...\n",
            "128/128 [==============================] - 5s 36ms/step - loss: 0.8237 - accuracy: 0.7229\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8236998915672302, 0.7229371070861816]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-C8DuYpf6f_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}