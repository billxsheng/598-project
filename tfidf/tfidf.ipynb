{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Define Imports"
      ],
      "metadata": {
        "id": "Lkhjw3gymQeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Concatenate, Input, Dropout, Dense, Dot\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2"
      ],
      "metadata": {
        "id": "lTKe-FCMmPTy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Constants"
      ],
      "metadata": {
        "id": "Wb8aMvvhmY54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 200\n",
        "HIDDEN_DIM = 100\n",
        "N_EPOCHS = 30\n",
        "TEST_SPLIT_SIZE = 0.2\n",
        "FEATURE_LIMIT = 5000\n",
        "\n",
        "stance_map = {'agree': 0, 'disagree': 1, 'discuss': 2, 'unrelated': 3}\n",
        "stance_map_inv = {0: 'agree', 1: 'disagree', 2: 'discuss', 3: 'unrelated'}"
      ],
      "metadata": {
        "id": "Py07dTNRmYZf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Methods to Extract Data"
      ],
      "metadata": {
        "id": "UHMSZhbis_AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reads _bodies.csv file and creates a dictionary from Body ID -> Body Text\n",
        "def get_body_dict(data_dir):\n",
        "    with open(data_dir, encoding='utf_8') as tb:\n",
        "        train_bodies = list(csv.reader(tb))\n",
        "        train_bodies_dict = {}\n",
        "        for i, line in enumerate(tqdm(train_bodies)):\n",
        "            if i > 0:\n",
        "                id = int(line[0])\n",
        "                train_bodies_dict[id] = line[1]\n",
        "\n",
        "    return train_bodies_dict\n",
        "\n",
        "# Reads _stances.csv file and returns headline, body, stance data\n",
        "def get_article_data(data_dir, train_bodies_dict):\n",
        "    with open(data_dir, encoding='utf_8') as ts:\n",
        "        train_stances = list(csv.reader(ts))\n",
        "\n",
        "        headlines, bodies, stances = [], [], []\n",
        "\n",
        "        for i, line in enumerate(tqdm(train_stances)):\n",
        "            if i > 0:\n",
        "                body_id = int(line[1].strip())\n",
        "\n",
        "                stances.append(line[2].strip())\n",
        "                headlines.append(line[0].strip())\n",
        "                bodies.append(train_bodies_dict[body_id])\n",
        "        return stances, headlines, bodies"
      ],
      "metadata": {
        "id": "keNDYCpotkIK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in CSV Data"
      ],
      "metadata": {
        "id": "lj78REkwtJ9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Reading in CSV data...')\n",
        "train_bodies_dict = get_body_dict(\"train_bodies.csv\")\n",
        "train_stances, train_headlines, train_bodies = get_article_data(\"train_stances.csv\", train_bodies_dict)\n",
        "\n",
        "competition_bodies_dict = get_body_dict(\"competition_test_bodies.csv\")\n",
        "test_stances, test_headlines, test_bodies = get_article_data(\"competition_test_stances.csv\", competition_bodies_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h59xFqV9tPdo",
        "outputId": "19c7ee09-a773-44e8-bd74-1d8ab7d61a5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading in CSV data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1684/1684 [00:00<00:00, 335114.48it/s]\n",
            "100%|██████████| 49973/49973 [00:00<00:00, 297049.87it/s]\n",
            "100%|██████████| 905/905 [00:00<00:00, 490990.18it/s]\n",
            "100%|██████████| 25414/25414 [00:00<00:00, 323956.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build TFIDF Vectorizer and Vectorize Documents"
      ],
      "metadata": {
        "id": "JLLeKKEhxgy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Initializing TFIDF Vectorizer...')\n",
        "# Converts collection of raw documents to a TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer(max_features=FEATURE_LIMIT)\n",
        "# Builds vocabulary from training set\n",
        "vectorizer.fit(train_headlines + train_bodies)\n",
        "\n",
        "print('Vectorizing Data...')\n",
        "# Transform documents to document-term matrix\n",
        "x_train_headlines = vectorizer.transform(train_headlines).toarray()\n",
        "x_train_bodies = vectorizer.transform(train_bodies).toarray()\n",
        "x_test_headlines = vectorizer.transform(test_headlines).toarray()\n",
        "x_test_bodies = vectorizer.transform(test_bodies).toarray()"
      ],
      "metadata": {
        "id": "PR9pFWq9ZDZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3626ff84-8a99-4efe-e593-85d46e17d74b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing TFIDF Vectorizer...\n",
            "Vectorizing Data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Stances and Create Train/Test Split"
      ],
      "metadata": {
        "id": "u1BMlkE809Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Encoding Stances...')\n",
        "# Fit encoder and return encoded labels\n",
        "encoded_train_stances = LabelEncoder().fit_transform(train_stances)\n",
        "# Transform labels to binary class matrix\n",
        "y_train = np_utils.to_categorical(encoded_train_stances, num_classes=4)\n",
        "encoded_test_stances = LabelEncoder().fit_transform(test_stances)\n",
        "y_test = np_utils.to_categorical(encoded_test_stances, num_classes=4)\n",
        "\n",
        "print('Creating train/test splits...')\n",
        "x_train_headlines, x_val_headlines, x_train_bodies, x_val_bodies, y_train, y_val = train_test_split(\n",
        "  x_train_headlines, x_train_bodies, y_train, test_size=TEST_SPLIT_SIZE)"
      ],
      "metadata": {
        "id": "fifZW4hPZM-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830dff03-a291-4412-a60b-bd29e1b78088"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding Stances...\n",
            "Creating train/test splits...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Model I/O"
      ],
      "metadata": {
        "id": "2FOIYiuQ4eA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Building Model I/O...')\n",
        "# Define model input for headlines\n",
        "input_headlines = Input(shape=(FEATURE_LIMIT,), name='input_headlines')\n",
        "# Define model input for bodies\n",
        "input_bodies = Input(shape=(FEATURE_LIMIT,), name='input_bodies')\n",
        "# Compute cosine similarity matrix\n",
        "cosine_similarity = Dot(axes=-1)([input_headlines, input_bodies])\n",
        "# Concatenate list of inputs\n",
        "concatenated_input = Concatenate()([input_headlines, input_bodies, cosine_similarity])\n",
        "\n",
        "# Add hidden layer\n",
        "hidden = Dense(HIDDEN_DIM, activation='sigmoid', name='dense_layer')(concatenated_input)\n",
        "# Add dropout layer\n",
        "hidden = Dropout(rate=0.6, name='dropout_layer')(hidden)\n",
        "# Add output layer\n",
        "out = Dense(4, activation='softmax', name='output_layer')(hidden)\n",
        "\n",
        "model = Model(inputs=[input_headlines, input_bodies], outputs=out)\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di7kNOsRZrMl",
        "outputId": "d3717b78-ff4d-41e9-8c30-6a6d35419735"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Model I/O...\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_headlines (InputLayer)   [(None, 5000)]       0           []                               \n",
            "                                                                                                  \n",
            " input_bodies (InputLayer)      [(None, 5000)]       0           []                               \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 1)            0           ['input_headlines[0][0]',        \n",
            "                                                                  'input_bodies[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 10001)        0           ['input_headlines[0][0]',        \n",
            "                                                                  'input_bodies[0][0]',           \n",
            "                                                                  'dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 100)          1000200     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_layer (Dropout)        (None, 100)          0           ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 4)            404         ['dropout_layer[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,000,604\n",
            "Trainable params: 1,000,604\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and Fit Model"
      ],
      "metadata": {
        "id": "lgGZByLe6Qi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print('Compiling Model...')\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print('Fitting Model...')\n",
        "model.fit([x_train_headlines, x_train_bodies], y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "          validation_data=([x_val_headlines, x_val_bodies], y_val))"
      ],
      "metadata": {
        "id": "yGEwQBcvZ__z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c151ad-fa12-4766-b67f-c35e8cef1091"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling Model...\n",
            "Fitting Model...\n",
            "Epoch 1/30\n",
            "200/200 [==============================] - 4s 15ms/step - loss: 0.9207 - accuracy: 0.6722 - val_loss: 0.7006 - val_accuracy: 0.7429\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.7590 - accuracy: 0.7294 - val_loss: 0.6478 - val_accuracy: 0.7431\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.6937 - accuracy: 0.7436 - val_loss: 0.5925 - val_accuracy: 0.7629\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.6379 - accuracy: 0.7590 - val_loss: 0.5364 - val_accuracy: 0.7739\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.5785 - accuracy: 0.7809 - val_loss: 0.4704 - val_accuracy: 0.8216\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.5205 - accuracy: 0.8056 - val_loss: 0.4142 - val_accuracy: 0.8384\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.4715 - accuracy: 0.8227 - val_loss: 0.3630 - val_accuracy: 0.8648\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.4259 - accuracy: 0.8432 - val_loss: 0.3221 - val_accuracy: 0.8848\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.3830 - accuracy: 0.8591 - val_loss: 0.2879 - val_accuracy: 0.9004\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.3539 - accuracy: 0.8706 - val_loss: 0.2618 - val_accuracy: 0.9093\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 2s 10ms/step - loss: 0.3240 - accuracy: 0.8836 - val_loss: 0.2394 - val_accuracy: 0.9172\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.3038 - accuracy: 0.8892 - val_loss: 0.2205 - val_accuracy: 0.9244\n",
            "Epoch 13/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2825 - accuracy: 0.8967 - val_loss: 0.2064 - val_accuracy: 0.9299\n",
            "Epoch 14/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2656 - accuracy: 0.9046 - val_loss: 0.1929 - val_accuracy: 0.9346\n",
            "Epoch 15/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2492 - accuracy: 0.9099 - val_loss: 0.1838 - val_accuracy: 0.9359\n",
            "Epoch 16/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2372 - accuracy: 0.9127 - val_loss: 0.1731 - val_accuracy: 0.9408\n",
            "Epoch 17/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2235 - accuracy: 0.9203 - val_loss: 0.1654 - val_accuracy: 0.9422\n",
            "Epoch 18/30\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.2131 - accuracy: 0.9225 - val_loss: 0.1588 - val_accuracy: 0.9439\n",
            "Epoch 19/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.2011 - accuracy: 0.9278 - val_loss: 0.1517 - val_accuracy: 0.9461\n",
            "Epoch 20/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1976 - accuracy: 0.9277 - val_loss: 0.1474 - val_accuracy: 0.9479\n",
            "Epoch 21/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.1853 - accuracy: 0.9315 - val_loss: 0.1432 - val_accuracy: 0.9484\n",
            "Epoch 22/30\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.1800 - accuracy: 0.9341 - val_loss: 0.1390 - val_accuracy: 0.9499\n",
            "Epoch 23/30\n",
            "200/200 [==============================] - 3s 13ms/step - loss: 0.1750 - accuracy: 0.9354 - val_loss: 0.1349 - val_accuracy: 0.9516\n",
            "Epoch 24/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1654 - accuracy: 0.9395 - val_loss: 0.1308 - val_accuracy: 0.9538\n",
            "Epoch 25/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1626 - accuracy: 0.9398 - val_loss: 0.1269 - val_accuracy: 0.9563\n",
            "Epoch 26/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1556 - accuracy: 0.9425 - val_loss: 0.1255 - val_accuracy: 0.9563\n",
            "Epoch 27/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1510 - accuracy: 0.9439 - val_loss: 0.1230 - val_accuracy: 0.9564\n",
            "Epoch 28/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1467 - accuracy: 0.9459 - val_loss: 0.1203 - val_accuracy: 0.9573\n",
            "Epoch 29/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1423 - accuracy: 0.9475 - val_loss: 0.1190 - val_accuracy: 0.9576\n",
            "Epoch 30/30\n",
            "200/200 [==============================] - 2s 11ms/step - loss: 0.1369 - accuracy: 0.9488 - val_loss: 0.1148 - val_accuracy: 0.9591\n",
            "CPU times: user 1min 8s, sys: 10.9 s, total: 1min 19s\n",
            "Wall time: 1min 10s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "laW5zm1m6UcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Model...')\n",
        "model.evaluate([x_test_headlines, x_test_bodies], y_test, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "xrt5dm3-aPPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e2f387-9721-4b06-c49c-b9b6da8c158f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Model...\n",
            "128/128 [==============================] - 1s 8ms/step - loss: 0.5217 - accuracy: 0.8526\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5217239856719971, 0.8525557518005371]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-C8DuYpf6f_F"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}